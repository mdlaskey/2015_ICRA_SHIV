%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[journal,transmag]{IEEEtran}% Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

\IEEEoverridecommandlockouts                              % This command is only needed if 
                                                          % you want to use the \thanks command

%\overrideIEEEmargins                                      % Needed to meet printer requirements.

% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed



\usepackage{amsmath,amssymb}

\usepackage{tikz,hyperref,graphicx,units,subfig}
\usepackage{subfig}
\usepackage{benktools}
\usepackage{caption}
\renewcommand{\captionfont}{\footnotesize}
\usepackage{sidecap,wrapfig}
\usepackage[ruled,vlined]{algorithm2e}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\abs}[1]{\lvert#1\rvert} 
\newcommand{\norm}[1]{\lVert#1\rVert}
%\newcommand{\suchthat}{\mid}
\newcommand{\suchthat}{\ \big|\ }
\newcommand{\ba}{\mathbf{a}}
\newcommand{\bb}{\mathbf{b}}
\newcommand{\bc}{\mathbf{c}}
\newcommand{\bd}{\mathbf{d}}
\newcommand{\bn}{\mathbf{n}}
\newcommand{\bp}{\mathbf{p}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bt}{\mathbf{t}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bbf}{\mathbf{f}}
\newcommand{\bzero}{\mathbf{0}}
\newcommand{\bG}{\mathbf{G}}
\newcommand{\bA}{\mathbf{A}}
\newcommand{\bW}{\mathbf{W}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\mX}{\mathcal{X}}
\newcommand{\mD}{\mathcal{D}}
\newcommand{\mG}{\mathcal{G}}
\newcommand{\mN}{\mathcal{N}}
\newcommand{\mW}{\mathcal{W}}
\newcommand{\mF}{\mathcal{F}}
\newcommand{\bZ}{\mathbf{Z}}

\newcommand{\bfc}{W}
\newcommand{\Qinf}{Q_{\infty}}
\newcommand{\st}[1]{_\text{#1}}
\newcommand{\rres}{r\st{res}}
\newcommand{\pos}[1]{(#1)^+}
\newcommand{\depth}{\operatorname{depth}}
\newcommand{\dist}{\operatorname{dist}}
\newcommand{\convhull}{\operatorname{ConvexHull}}
\newcommand{\minksum}{\operatorname{MinkowskiSum}}

\title{\LARGE \bf
Efficient Planar Sample-Based Grasp Planning with Uncertainty Using Multi-Armed Bandit Models [v3 Feb 12, 2015 ] }


\author{Michael Laskey$^1$,Jeff Mahler$^1$, Zoe McCarthy$^1$,  Florian T. Pokorny$^3$, Sachin Patil$^1$,\\ Jur Van Den Berg$^4$,  Danica Kragic$^3$, Pieter Abbeel$^1$, Ken Goldberg$^2$% <-this % stops a space
\thanks{$^1$Department of Electrical Engineering and Computer Sciences; {\small \{mdlaskey, zmccarthy, jmahler, sachinpatil, pabbeel\}@berkeley.edu}}%
\thanks{$^2$Department of Industrial Engineering and Operations Research and Department of Electrical Engineering and Computer Sciences; {\small goldberg@berkeley.edu}}%
\thanks{$^{1-2}$ University of California, Berkeley;  Berkeley, CA 94720, USA}%
\thanks{$^3$Computer Vision and Active Perception Lab, Centre for Autonomous Systems, School of Computer Science and Communication, KTH Royal Institute of Technology, Stockholm, Sweden {\small \{fpokorny, dani\}@kth.se}}%
\thanks{$^4$Google; Amphitheatre Parkway, Mountain View, CA 94043, USA {\small jurvandenberg@gmail.com}}%
} 

\newtheorem{theorem}{Theorem}

\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
\textit{Abstract---}Sampling perturbations in shape, state, and control can facilitate grasp planning in the presence of uncertainty arising from noise, occlusions, and surface properties such as transparency and specularities.  Monte-Carlo sampling is computationally demanding, even for planar models. We consider an alternative based on the multi-armed bandit (MAB) model for making sequential decisions, which can apply to a variety of uncertainty models.  We formulate grasp planning as a ``budgeted multi-armed bandit model" (BMAB) with finite stopping time to minimize ``simple regret", the difference between the expected quality of the best grasp and the expected quality of the grasp evaluated at the stopping time.  To evaluate MAB-based sampling, we compare it with Monte-Carlo sampling for grasping an uncertain planar object with shape uncertainty defined by a Gaussian process implicit surface (GPIS), but the method is also applicable to other models of uncertainty.  We derive distributions on contact points, surface normal, and center of mass under shape uncertainty and use these to formulate the associated MAB model, finding that it computes grasps of similar quality to Monte-Carlo sampling and can reduce computation time by an order of magnitude.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}


%\vspace{10pt}
%\todo{Get High res GPIS visualizations, Incorporate next round of feedback}

Consider a robot processing orders in a warehouse, where it frequently encounters new consumer products and must process them quickly.
The robot may need to rapidly plan grasps for these objects without prior knowledge of object shape, pose and material properties like friction coefficient or center of mass. 
Furthermore, the robot may not be able to measure these quantities exactly due to sensor imprecision and missing data, which could result from occlusions or surface properties such as transparency or reflective surfaces.

\begin{figure}%
    \centering
%     \subfloat{{\includegraphics[width=8cm]{figures/cup.jpg} }}%
    
%       \qquad
  
     \subfloat{{\includegraphics[width=8cm]{matlab_figures/pfc.eps} }}%
   
    \caption{\todo{New teaser photo, not sure if we should have some sort of real object or not}(Top Left) Image of a common household measuring cup. (Top Right) Image from a PR2 Primesense camera that reflects the uncertainty that can be induced in objects from transparency. (Bottom) Comparision of Multi-Armed Bandit Techniques (Bayes UCB, Thompson, Gittins) vs. Monte-Carlo sampling to determine the best grasp in a set of 1000 grasps. As you can see the bandit techniques converge in simple regret Eq. \ref{eq:simple_regret} a magnitude faster than the traditional approach of Monte-Carlo sampling to determine the highest quality grasp.  }%
    \label{fig:rot_shapes}%
\end{figure}

Analytic grasp quality metrics have been developed to determine the stability of a grasp when all the parameters of the object and robot manipulator are exactly known.
One common measure of stability is force closure, the ability to resist external forces and torques in arbitrary directions~\cite{}.
Grasps in force closure can be further ranked by the relative magnitude of forces and torques that must be exerted by the gripper to resist external perturbations~\cite{ferrari1992}.
Recent works have explored computing the probability of a grasp achieving the force closure condition given uncertainty in parameters such as pose~\cite{christopoulos2007handling, weisz2012pose, kim2012physically} and object shape~\cite{kehoe2012estimating, mahler2015gp}.
Many methods for evaluating grasp quality in the presence of uncertainty use exhaustive Monte-Carlo sampling over the possible values of uncertain quantities~\cite{christopoulos2007handling, kim2012physically, weisz2012pose, kehoe2012estimating, kehoe2012towards} which can be very time consuming.
We are interested in ruling out grasps with a low probability in only a few samples and allocate more sampling effort to grasps that are likely to be high quality.

The multi-armed bandit (MAB) model for sequential decision making problems~\cite{barto1998reinforcement, lai1985asymptotically, robbins1952some} provides a formal way to reason about allocating sampling effort to grasps such that the grasp(s) with highest quality can be determined in as few samples as possible.
In a standard MAB there are a set of possible options (or `arms' in the literature~\cite{barto1998reinforcement}) that each return a numeric reward from a stationary distribution.
The goal in a MAB problem is to sequentially select ones of the possible options such that a measure of expected reward is maximized.
Solutions to the MAB model are particularly useful in applications where it is too expensive to fully evaluate a set of options; for example, in optimal design of clinical trials~\cite{simon1989optimal}, market pricing~\cite{rothschild1974two}, and choosing strategies for games~\cite{st2012online}.
The budgeted multi-armed bandit model \cite{madani2004budgeted} is a specialization of the MAB model where an agent has a fixed number of decisions to make before choosing the best option.
The objective is to maximize the expected reward of the decision made at the stopping time, or equivalently to minimize ``simple regret", which is the difference between the true expected reward of an optimal arm and the true expected reward of the arm pulled at the stopping time.

Our main contribution is formulating the problem of ranking a set of candidate grasps according to a quality metric in the presence of uncertainty as a budgeted multi-armed bandit problem. %\todo{Jeff: probably needs to be more specific here, unless we formally describe how to do it in an arbitrary model}.
We study this formulation using probability of force closure~\cite{christopoulos2007handling, weisz2012pose, kehoe2012toward} as a quality metric under uncertainty in pose, shape, robot motion, and friction coefficient. 
We model shape uncertainty using Gaussian process implicit surfaces (GPISs), a Bayesian representation of shape uncertainty that has been used in various robotic applications~\cite{dragiev2011, hollinger2013}. 
Uncertainty in pose is represented as a normal distributions around the orientation and translation of the object.
Uncertainity in motion is represented as a normal distribution around the end point of a planned gripper trajectory and uncertainty in friction coefficient is a normal distribution around an expected friction coefficient.

Our approach of using BMAB is applicable to any distributions that can be sampled from, however performance could potentially vary. 
We compare the performance of several popular algorithms for solving the BMAB problem: Thompson sampling, and Gittins indices. 
\todo{Going to fill bottom paragraph in later}
Initial results suggest a promising avenue with a Xx improvement over  the traditional Monte-Carlo integration and Xx improvement in the experiments that we tried. 


\section{Related Work}

Past work on grasping under uncertainty has considered shape uncertainty \cite{goldberg1990bayesian, stulp2011learning}, uncertainty in contact locations with an object \cite{zheng2005}, and uncertainty in object pose \cite{christopoulos2007handling, weisz2012pose, kim2012physically}.
The effect of uncertainty in object geometry on grasp selection has been studied for spline representations of objects~\cite{christopoulos2007handling}, extruded polygonal mesh models~\cite{kehoe2012estimating, kehoe2012toward}, and point clouds~\cite{hsiao2011bayesian}.
A common method for evaluating a probabilistic grasp quality measure is to use Monte-Carlo sampling~\cite{christopoulos2007handling, kehoe2012estimating, kehoe2012toward}, which involves exhaustively sampling from distributions on random quantities and averaging the quality over these samples to approximate an expected value~\cite{caflisch1998monte}.
Exhaustive sampling can be computationally expensive, which motivated the use of Cloud Computing to distribute sampling effort~\cite{kehoe2012toward}.

To further address the computational complexity, Kehoe et al.~\cite{kehoe2012estimating} demonstrated a procedure for finding a minimum bound on expected grasp quality given shape uncertainty, which reduced the number of samples needed in Monte-Carlo sampling to choose the highest quality grasps. However, the proposed adaptive sampling approach pruned grasps using only the sample mean and did not utilize any estimates of how accurate the current sample mean is, which in practice could lead to good grasps being thrown away.
Laaksonen et al.~\cite{laaksonen2012probabilistic} used Markov Chain Monte-Carlo (MCMC) sampling to estimate grasp quality and object pose  under shape and pose uncertainty when the robot is able to obtain new information via tactile sensor.
MCMC provides a Bayesian framework for inference with a hidden state, but it can be slow to converge to the correct distribution due to burn in and mixing conditions~\cite{andrieu2003introduction}.

 \todo{Michael: should we include this next section on GPIS}
We chose to study our MAB sampling method on distributions for friction coefficient, pose, motion and shape. For shape uncertainty we decided to use a Gaussian process implicit surface representation. Our decision to use this uncertainty model is based on GPIS's ability to combine different modes of noise observations such as tactile, laser and visual~\cite{rasmussen2006, williams2007, dragiev2011} and its recent use in modeling uncertainty for a number of robotic applications.
Hollinger et al. used GPIS as a model of uncertainty to perform active sensing on the hulls in underwater boats \cite{hollinger2013}.
Dragiev et al. showed how GPIS can enable a grasp controller on the continuous signed distance function \cite{dragiev2011}.
Mahler et al. used the GPIS representation to find locally optimal anti-podal grasps by framing grasp planning as an optimization problem \cite{mahler2015gp}.  However, this relied on an approximation to grasp quality without guarantees on accuracy. We propose an adaptive sampling approach known as the Multi-Armed Bandit Model.




\section{Preliminaries and Problem Definition}
We consider selecting a grasp on object from a given set of candidate grasps.
We formulate this problem for grasping a planar object from above using parallel-jaw grippers.
We assume that the object is rigid and remains stationary throughout the grasp.
In this work we consider uncertainty in shape, pose, robot motion, and friction coefficient and we assume that distributions on these quantiites are given.
In this section, we formally define our grasping model, formalize our sources of uncertainty, introduce our metric for grasp quality, and finally define our grasp planning objective.

%Before we present the problem definition, we introduce a way to evaluate the quality of a grasp and our grasping model, the line of action. We also introduce a graphical model to represent the distributions on friction coefficient, motion, pose and shape. 


\subsection{Candidate Grasp Model}
Our candidate grasp model is illustrated in Fig.~\ref{fig:grasp_model}.
Let $d$ denote the dimensionality of the shape representations we are using to select grasps and $m$ denote the number of jaws on the robotic gripper.
In this work we formulate the MAB problem for 2-dimensional shapes using parallel-jaw grippers, so $d=2$ and $m=2$.
In this work we also assume a finite width for each parallel jaw $w_j \in \mathbb{R}$.

Similar to~\cite{christopoulos2007handling}, we parameterize a grasp using a {\it line of action} for each gripper jaw, where each line of action is a 1D curve $\gamma(t): [0,1] \rightarrow \mathbb{R}^d$ with endpoints $\gamma(0) = \ba$ and $\gamma(1) = \bb$.
The line of action defines the trajectory that a jaw follows as the gripper closes around a shape.
A {\it grasp plan} is the set of lines of action for each of the jaws, $\Gamma = \{\gamma_1(\cdot),...,\gamma_m(\cdot)\})$ \cite{}.
For parallel-jaw grippers, $\Gamma = \{\gamma(t), \gamma(1 - t)\}$, since the two jaws approach the shape in opposite directions.
Furthermore, in this work we consider only straight lines of action.
The line of action model allows us to compute perturbations to the contact points and normals that occur due to shape uncertainty.
%We chose of the line of action model because perturbations to a surface resulting from shape uncertainty lead to changes in the location of contact with a surface, and the line of action allows us to compute these new locations.

Given a grasp plan and a deterministic shape, we define the {\it contact points} as the spatial locations at which the jaws come into contact with the object when following the given plan, $\bc_1, ..., \bc_m \in \mathbb{R}^d$.
We also refer to the unit outward pointing surface normals at the contact points as $\bn_1, ..., \bn_m \in \mathbb{R}^d$ and the object center of mass as $\bz \in \mathbb{R}^d$.
Together these form the set of grasp parameters $g = (\bc_1, ..., \bc_m, \bn_1, ... \bn_m, \bz)$ that enable us to evaluate the forces and torques that a given grasp can apply to an object.

%\begin{figure}[ht!]
%\centering
%\includegraphics[width = 6cm, height = 4cm]{figures/Slide01.jpg}
%\caption{Illustration of a grasp plan $\Gamma$ composed of two lines of action, $\gamma_1(t)$ and $\gamma_2(t)$}
%\vspace*{-10pt}
%\label{fig:line_of_action}
%\end{figure}

\begin{figure}[t!]
\centering
\includegraphics[width = 8cm, height = 6.5cm]{figures/grasp_model.jpg}
\caption{llustration of our grasping model for parallel jaw grippers on a GPIS model of a marker with shape uncertainty near the object center. Jaw placements are illustrated by a red direction arrow and line. The grasp plan consists of a line of action $\gamma(t)$ with endpoints $\ba$ and $\bb$. When following the grasp plan, the jaws contact the shape at locations $\bc_1$ and $\bc_2$ with outward pointing unit surface normals $\bn_1$ and $\bn_2$. Together with the center of mass of the object $\bz$, these values can be used to determine the forces and torques that a grasp can apply to an object. \todo{Jeff: Up to this point I don't believe the reader has seen a GPIS. We will replace the marker with a deterministic shape, but this figure gives a good idea of what we want to illustrate here.}}
\vspace*{-4ex}
\label{fig:grasp_model}
\end{figure}

\subsection{Sources of Uncertainty}
In this work we consider uncertainty in shape, pose, robot motion, and friction coefficient.
Fig. \ref{fig:graphical_model} illustrates a graphical model of the relationship between these sources of uncertainty.
In this section we describe each source of uncertainty and our model of the uncertainty.
We wish to emphasize that the models of uncertainty described in this work are not the only models that may be used with MAB algorithms and that the reader may choose parameters and distributions that best fit their needs, however performance is subject to vary on empirical results. 

\subsubsection{Shape Uncertainty}

Uncertainty in object shape results from sensor noise and missing sensor data, which can occur due to transparency, specularity, and occlusions~\cite{mahler2015gp}.
Following ~\cite{laskey2015bandits, mahler2015gp} we represent the distribution over possible surfaces given sensing noise using a Gaussian process implicit surface (GPIS).
A GPIS represents a distribution over signed distance functions (SDFs), a surface representation commonly used in 3D reconstruction and SLAM \cite{}.
A SDF is a real-valued function $f: \mathbb{R}^d \rightarrow \mathbb{R}$ that is greater than 0 outside the object, 0 on the surface and less than 0 inside the object.
A GPIS is a gaussian distribution over SDF values at a fixed set of query points $\mX = \{\bx_1, ... \bx_n\}, \bx_i \in \mathbb{R}^d$, $f(\bx_i) \sim \mN(\mu_{f}(\bx_i),\Sigma_{f}(\bx_i))$, where $\mu_{f}(\cdot)$ and $\Sigma_{f}(\cdot)$ are the mean and covariance functions of the GPIS.
See Mahler et al.  for details on how to train a mean and covariance function and sample shapes from a GPIS \cite{mahler2015gp}.
In this work, we set $\mX$ to a uniform $M \times M$ grid of points with square cells.
For convenience, in later sections we will refer to the GPIS parameters as $\theta = \left( \mu_{f}(x), \Sigma_{f}(x) \right)$. 


\subsubsection{Pose Uncertainty}
In typical robotics applications the pose of objects in the environment is determined by registering the object frame-of-reference to the control frame-of-reference used for grasp execution.
Therefore pose uncertainty may come from either a) uncertainty about the registration of the robot's grasping frame-of-reference to its sensing frame-of-reference and b) uncertainty about the pose of known object models in the robot's sensor data.
In practice this uncertainty may be quantified based on the algorithms used to register these frames to one another.
The effects of pose uncertainty on robotic grasping has been studied by~\cite{weisz2012pose, kim2012physically}. % cite Ben's RSS workshop paper here

In 2-dimensional space, the pose of an object $T$ is a member of the Lie Group $SE(2)$.
This matrix is defined by a rotation angle $\phi$ and two translation coordinates $\bt = (t_x, t_y)$, summarized in parameter vector $\mathbf{\xi} = (\phi, \bt)^T \in \mathbb{R}^3$:

\vspace{-2ex}
\begin{align*}
	T &= \left[  \begin{array}{ccc}
		\cos(\phi) & -\sin(\phi) & t_x \\
		\sin(\phi) & \cos(\phi) & t_y \\
		0 & 0 & 1
		\end{array} \right] .
\end{align*}

One challenge with pose is that the pose matrix $T$ is used to apply pose perturbations to an object in practice, but uncertainty is mathematically more easily quantified in terms of the pose parameters $\xi$.
Folowing Barfoot and Furgale, we assume that we are given a mean pose matrix $\bar{T} \in SE(3)$ and zero-mean Gaussian uncertainty on the pose parameters $\mathbf{\xi} \sim \mN \left( \mathbf{0}, \Sigma_{\xi} \right)$. \cite{barfoot2014Pose}.

 
 \subsubsection{Motion Uncertainty}
In practice a robot may not be able to execute a desired grasp plan $\Gamma$ exactly due to slight errors in actuation or feedback measurements used for trajectory following~\cite{kehoe2012estimating}.
In this work, we model motion uncertainty as Gaussian uncertainty around the angle of approach and centroid of a straight line grasp plan $\Gamma$.
Formally, let $\hat{\by} = \frac{1}{2} (\ba + \bb)$ denote the center of a planned line of action $\gamma(t)$ and $\hat{\psi}$ denote the angle that the planned line $\bb - \ba$ makes with the x-axis of the 2D coordinate system on our shape representation.
Then the random center $\by \sim \mN(\hat{\by}, \Sigma_y)$ and the random angle $\psi \sim \mN(\hat{\psi}, \sigma_{\psi}^2)$.
For shorthand in the remainder of this paper we will refer to the random motion parameters as $\rho = \{\by, \psi \}$.
In practice $\Sigma_{y}^2$ and $\sigma_{\psi}^2$ might be set from repeatibility measurements for a robot \cite{mooring1986determination}.

 \subsubsection{Friction Uncertainty}
As shown in \cite{zheng2005}, uncertainty in friction coefficient can cause grasp quality to significantly vary.
However, friction coefficients may be uncertain due to factors such as material between a gripper and an object (e.g. dust, water, moisture), variations in the gripper material due to manufacturing tolerances, or misclassification of the object surface to be grasped.
We model uncertainty in friction coefficient as Gaussian noise, $\mu \sim \mN(\hat{\mu},\sigma_{\mu}^2)$. 
 
\subsection{Grasp Quality}\label{sec:grasp_sample}
We measure the quality of grasp using the probability of force closure~\cite{weisz2012pose, kim2012physically, kehoe2012estimating, kehoe2012toward} given a grasp plan $\Gamma$, which we denote $P_F(\Gamma)$.
Force closure measures the ability to resist external wrenches, or force and torques vectors, assuming the grasp can apply infinite force.

Formally, force closure is a binary-valued quantity $F$ that is 1 if a grasp can resist wrenches in arbitrary directions and 0 otherwise.
Let $\mW \in \mathbb{R}^6$ denote the contact wrenches derived from contact locations $\bc_1, ... \bc_m$, normals $\bn_1, .., \bn_m$, friction coefficient $\mu$, and center of mass $\bz$ for a given grasp and shape.
If the origin lies within the convex hull of $\mW$, then the grasp is in force closure\cite{li1988task}.
In this work we rank grasps using the probability of force closure given uncertainty in shape, pose, robot motion, and friction coefficient~\cite{christopoulos2007handling, kehoe2012toward}:
%\vspace{-2ex}
\begin{align*}
	P_F(\Gamma) &= P(F = 1 | \Gamma, \theta, \xi, \rho, \mu).
\end{align*}

 
To estimate $P_F(\Gamma)$, we generate  samples from each of the above distributions in sequence using the relationships defined by the graphical model in Fig. \ref{fig:graphical_model}.To sample from $p_F(\Gamma)$, we need to sample from the distributions associated with a line of action $p(\textbf{n}_i,\textbf{c}_i|\gamma_i(t),\xi,\theta, \rho)$. Using Bayes rule  we can rewrite this as 
 
 \vspace{-2ex}
 \begin{align*}
 &p(\textbf{n}_i,\textbf{c}_i |\gamma_i(t),\theta,\xi,\rho)=\\
 &p(\textbf{n}_i|\textbf{c}_i,\theta)p(\textbf{c}_i|\gamma_i(t),\theta,\rho,\xi)
 \end{align*}

 
Mahler et al \cite{mahler2015gp}, describes how to draw shape sample from a GPIS model, which is used to compute $p(\textbf{c}_i|\gamma_i(t),\theta,\rho,\xi)$ along with the other sampled distribution on pose ($\xi$) and motion ($\rho$). We then use these quantities to determine the grasp parameters $g$. Finally, we compute the forces and torques that can be applied by $g$ to form the contact wrench set $\mW$ and evaluate the force closure condition.


%Let Q be the $L^1$ version of the metric depends on the contact points $\textbf{c}_1,...,\textbf{c}_m \in \mathcal{R}^2$, surface normals $\textbf{n}_1,...,\textbf{n}_m \in \mathcal{R}^2$, center of mass $\textbf{z}$ and friction coefficient $\mu$. The metric is evaluated by constructing a convex hull around the wrenches made up of those parameters and finding the radius of the largest unit ball centered at the origin in wrench space. If the convex hull  encloses the origin then the grasp is in ``force-closure,'' meaning the grasp can resist any external wrenches if enough force is used. A grasp can be parameterized by the following tuple $g = ( \textbf{c}_1,...,\textbf{c}_m,\textbf{n}_1,...,\textbf{n}_m,\mu, \textbf{z} )$\cite{pokorny2013classical}.
%
%In this work we use the probability of achieving force closure, or $P(Q>0)$, \cite{christopoulos2007handling}\cite{kehoe2012toward}, to rank grasps . $P(Q>0)$ may be computed by sampling from distributions on pose (rotation and translation of the object), shape and material properties (friction coefficient) and averaging the qualities that are computed.

\begin{figure}[ht!]
\centering
\includegraphics[width = 6cm, height = 6cm]{figures/Graphical_Model.jpg}
\caption{A graphical model that illustrates the relationship between the different types of uncertainty in an object. Center of Mass uncertainty is dependent on the pose and shape of the object, however friction coefficient is independent of all other types.}
\vspace*{-10pt}
\label{fig:graphical_model}
\end{figure}

\subsection{Objective}

Given the sources of uncertainty and their relationships as described above, our goal is to find the grasp that maximizes the probability of force closure from a set of $P$ prespecified candidate grasps $\mG = \{\Gamma_1, ..., \Gamma_P\}$:

\vspace{-2ex}
\begin{align}
\Gamma^* &= \underset{\Gamma \in \mG}{\text{argmax }} P\left( F = 1 | \Gamma, \theta, \xi, \rho, \mu \right) 
\end{align}

Since we only can approximate the probability of force closure, with samples drawn from the distribution $P_F(\Gamma)$ our objective is rewritten as: 

\vspace{-2ex}
\begin{align}
\Gamma^* &\approx \underset{\Gamma \in \mG}{\text{argmax }} P\left( F = 1 | \Gamma, \theta, \xi, \rho, \mu \right) \label{eq:problem_def}
\end{align}

One method to solve Equation ~\ref{eq:problem_def} is to exhaustively evaluate $P_F(\Gamma)$ for all grap plans in $\mG$ using Monte-Carlo integration and then sort the plans by this quality metric.
This method has been evaluated for shape uncertainty~\cite{christopoulos2007handling, kehoe2012estimating} and pose uncertainty~\cite{weisz2012pose} but is computationally expensive since it may require many samples for each of a large set of candidates to converge to the true value.
More recent works have considered adaptive sampling to discard grasp plans that are not likely to be optimal without fully evaluating their quality~\cite{kehoe2012toward}. In this work we show that this objective can be framed as a budgeted multi-armed bandit (BMAB) problem, which offers stronger theoretical and empirical performance \cite{agrawal2011analysis}\cite{chapelle2011empirical}.

\section{Multi-Armed Bandits for Grasp Selection}
\label{sec:MAB}
%While a standard approach to solving the problem in Eq. \ref{eq:problem_def} would be to perform Monte-Carlo integration on each $\Gamma_i$ and compute the probability of force closure, we
We propose framing the problem in the multi-armed bandit (MAB) model and forming a policy for iteratively selecting which grasp to evaluate based on the probability of force closure estimate from the samples so far.
The goal of the MAB approach is to allocate more sampling effort to grasps that appear to have higher quality based on the evaluation performed so far.

\subsection{MAB Model}
The multi-armed bandit model, originally described by Robbins \cite{robbins1985some}, is a statistical model of an agent attempting to make a sequence of correct decisions while concurrently gathering information about each possible decision.
Solutions to the multi-armed bandit model have been used in applications for which evaluating all possible options is expensive or impossible, such as the optimal design of clinical trials~\cite{simon1989optimal}, market pricing~\cite{rothschild1974two}, and choosing strategies for games~\cite{st2012online}. 

In a traditional MAB problem, a gambler has $K$ independent slot machines, or ``arms'' to play.
When an arm is played (or ``pulled'' in the literature), it returns an amount of money from a fixed reward distribution $P_k, k = 1, ..., K$ that is unknown to the gambler.
The goal of the gambler is to come up with a method for determining which arms to pull, how many times to pull each arm, and what order to pull them in such that the average cumulative rewards are maximized over many pulls.
If the gambler knew the machine with the highest expected reward, the gambler would only pull that arm.
However, since the reward distributions are unknown, a successful gambler needs to trade off exploiting the arms that currently yields the highest reward and exploring new arms to see if they give better rewards on average.
Developing a policy that successfully trades between exploration and exploitation to maximize average reward has been the focus of extensive research since the problem formulation \cite{bubeck2009pure}, \cite{robbins1985some}, \cite{bergemann2006bandit}.

Success in MAB problems is commonly measured in terms of {\it regret}, the difference between the expected optimal reward and the expected reward of the selected arm on a single pull.
Traditional bandit algorithms minimize cumulative regret, the sum of regret over the entire sequence of arm choices.
Lai and Robbins showed that an optimal solution to the bandit problem is bounded by a logarithmic function of the number of arm pulls~\cite{lai1985asymptotically}.
They presented an algorithm called (Upper Confidence Bound) UCB that obtains this bound asymptotically~\cite{lai1985asymptotically}.
The algorithm maintains a confidence bound on the distribution of reward based on prior observations and pulls the arm with the highest upper confidence bound.
Many variants of UCB have thus been proposed~\cite{cesa2006prediction}. 
Since then a several other algorithms have been shown to achieve this bound, such as the Gittins index policy~\cite{weber1992gittins} and Thompson sampling for certain reward distributions~\cite{agrawal2011analysis}.

\subsection{Grasp Planning as a Multi-Armed Bandit}
In this work, we frame the grasp selection problem of \secref{objective} as a multi-armed bandit problem.
Each arm corresponds to a different grasp plan and pulling an arm corresponds to sampling from the graphical model in Fig. \ref{fig:graphical_model} and evaluating the force closure condition.
Since force closure is a binary value, we can think of each grasp plan $\Gamma_i$ as having a Bernoulli reward distribution with probability of success $P_F(\Gamma_i)$.
Thus, the expected value of the force closure condition for grasp $\Gamma_i$ is $\mu_i = E[F | \Gamma_i, \theta, \xi, \rho, \mu] = P_F(\Gamma_i)$. One can think of the proposed algorithm as an anytime algorithm, because at a unknown stopping time $T_s$, the multi-armed bandit model must return the current highest estimated grasp plan. Minimizing the expected instantaneous regret, the difference quality of grasp chose and the best grasp in the set, at stopping time, $T_s$, is equivalent to maximizing $P_F$ over the set of candidate grasp plans:

\vspace{-2ex}
\begin{align*}
	\underset{\Gamma_i \in \mG}{\text{argmin }}\mu^{*} - \mu_{i} &= \underset{\Gamma_i \in \mG}{\text{argmax }}\mu_{i} \\
	&=  \underset{\Gamma_i \in \mG}{\text{argmax }} P_F(\Gamma_i) \\
	&= \Gamma^{*}
\end{align*}

In Section \ref{sec:bandit_algorithm}, we will discuss some of the most popular algorithms for solving the multi-armed bandit problem in detail. 

\section{Algorithms for MAB}\label{sec:bandit_algorithm}
In this work, we are particularly interested in Bayesian MAB algorithms that use previous samples to form a belief distribution on the likelihood of the parameters specifying the distribution of each arm \cite{weber1992gittins,agrawal2011analysis}, as these methods have been shown empirically to outperform frequentist algorithms (e.g., UCB) on real datasets such as ad placement~\cite{chapelle2011empirical, bachman2013greedy}.
%However, recently Bayesian approachs have gained interest in the MAB community due to their empirical success on real world problems such as ad suggestions \cite{kaufmann2012bayesian} \cite{agrawal2011analysis}.
%In Bayesian algorithms, the agent maintains a belief distribution over the reward distribution on the arms.

Bayesian algorithms maintain a belief distribution on the grasp quality distributions for each of the candidate grasps to rank. In the case of using force closure $F$ to measure quality, $P_F$ for each candidate grasp is a Bernoulli random variable and the Bayesian conjugate prior is a Beta distribution. 
Beta distributions are specified by shape parameters $\alpha$ and $\beta$, where ($\alpha >0$ and $\beta >0$).
Typically the uniform prior distribution on probability of force closure for each grasp $i$ at time $t = 0$, $\alpha_{i, 0} =1 $ and $\beta_{i, 0} = 1$, would be used used to initialize the algorithm~\cite{}. 
Theoretical results have shown that several algorithms for Beta-Bernoulli reward distributions are capable of achieving the lower bound described by Lai and Robbins~\cite{gittins1983dynamic, agrawal2011analysis, kaufmann2012bayesian}.
%Furthermore in an empirical study Bayesian methods have been shown to outperform the UCB family \cite{chapelle2011empirical}. 
%See \cite{} for a review of bayesian methods in multi-armed bandit problems. 

%In the context of grasping, the reward for achieving force close on a sample from the uncertain parameters is a Bernoulli random variable with probabilty of success $\theta$.
%%The distribution that describes whether an event is $\lbrace 0, 1 \rbrace$ is known as a Bernoulli distribution and can be described by the parameter $\theta$ or the probability an event occurs.
%In the Bayesian setting we treat $\theta$ as belonging to a distribution.
%A common choice for such a distribution is the Beta distribution, which is the conjugate prior of the Bernoulli distribution.
%One benefit of a conjugate prior is that the posterior update of the belief distribution is of the same form as the original prior, simplifying sampling and analysis.
%Beta distributions are specified by shape parameters $\alpha$ and $\beta$, where $\alpha >0$ and $\beta >0$.
%The mean of the Beta distribution is given by $\alpha/(\alpha+\beta)$.
%To update the prior Beta distribution one adds the count of observed successes of the event to $\alpha$ and the count of the observed failures to $\beta$
%Often the prior $\alpha =1 $ and $\beta =1$ is used before any rewards are observed, which leads to a uniform distribution on $\theta$. 

One benefit of the Beta prior on Bernoulli reward distributions is the elegant updates to the belief distribution after observing rewards from arm pulls.
Let $n_i$ denote the number of times grasp plan $\Gamma_i$ has been sampled.
Then after observing $S_i$ force closure conditions for grasp $\Gamma_i$, the posterior of the Beta can be computed as $\alpha_{i, n_i} = \alpha_{i, 0} + S_i, \beta_{i, n_i} = \beta_{i, 0} + n_i - S_i$, where $\alpha_{i,0}$ and $\beta_{i,0}$ are the prior shape parameters for $\Gamma_i$ before any samples are evaluated.
%Given a proposed grasp plan $\Gamma_i$ with current posterior belief $\alpha_i, \beta_i$, , we draw samples from the shape distribution $P(\theta)$, the distribution on pose $P(\xi)$, distribution on motion $P(\rho)$ and the distribution on friction coefficient $P(\mu)$.
%The distribution on force closure can then be estimated as Beta- Bernoulli Process with shape parameters $\alpha$ and $\beta$.
Given the current belief $\alpha_{i, n_i}, \beta_{i, n_i}$ on $P_F$ for a grasp plan $\Gamma_i$, the algorithm can predict the probability of force closure on the next iteration by taking the expected value:
%Thus, we can write the expected probability of force closure as follows

\vspace{-2ex}
\begin{align}\label{eq:shape_sampling}
P_F(\Gamma) = \frac{\alpha}{\alpha + \beta}
\end{align}

Whats interesting in the context of a Bayesian BMAB problem our graphical model in Fig. \ref{fig:graphical_model}, is now equivalent in terms of inference to Fig. \ref{fig:beta_model} and we only need to estimate $\alpha$ and $\beta$ to determine grasp quality. Regardless of the distributions in Fig. \ref{fig:graphical_model}, we are still able to maintain the theoretical guarantees given by the Bayesian MAB algorithms because the probability of force closure is a Beta-Bernoulli Process on the convergence of the solution being near optimal \cite{agrawal2011analysis}
\cite{weber1992gittins} , which we will now discuss for each of the proposed algorithms.


\begin{figure}[ht!]
\centering
\includegraphics[width = 2cm, height = 4cm]{figures/Slide9.jpg}
\caption{A graphical model that illustrates the relationship between the Bernoulli distribution of the probability force closure and its conjugate prior Beta distribution that has two shape parameters $\alpha$ and $\beta$ }
\vspace*{-10pt}
\label{fig:beta_model}
\end{figure}


%In practice, when the distribution on the rewards of arms is not known, the empirical methods such as $\epsilon-$greedy have shown to have better performance in some situations \cite{kuleshov}.

%In our case we only care about the regret at the time our decision of the optimal grasp needs to be made, decoupling the exploration and exploitation stages.

We describe three popular Bayesian MAB algorithms below for the Beta belief distribution.

\subsection{The Gittins Index Method} 
One MAB method is to treat the problem as an Markov Decision Process (MDP) and use Markov Decision theory. Formally, a MDP is defined as a set of possible of states, a set of actions, a set of transition probabilities between states, a reward function, and a discount factor \cite{barto1998reinforcement}.
In the Beta-Bernoulli MAB case, the set of actions is the $K$ options and the states are the Beta prior on each option. A key insight though was given by Gittins, who showed that instead of solving the $K$-dimensional MDP one can instead solve $K$ 1-dimensional optimization problems. Generally the computation of the Gittins indices is too expensive, however in the Beta-Bernoulli case it is actually possible \cite{kaufmann2012bayesian}.

Methods, such as Value Iteration, exist to determine optimal policies with respect to the discount factor $\gamma$ \cite{weber1992gittins,barto1998reinforcement}. However, the curse of dimensionality effects performance because if you have $K$ arms, a finite horizon of $T$ and a Beta-Bernoulli distribution on your options then your state space is exponential in $K$. A key insight though was given by Gittins, who showed that instead of solving the $K$-dimensional MDP one can instead solve $K$ 1-dimensional optimization problems: for each option $i$, $i= 1,...,k$, and for each state $x_t^i = \lbrace \alpha_0 +S_t, \beta_0 +F_t \rbrace^i$, where $S_t$ and $F_t$ correspond to the number of success and failures at pull $t$ and the state $x_t^i$ is the Beta prior for option $i$. 

\vspace{-2ex}
\label{eq:git_indices}
\begin{align}
	v^i(x^i) = \underset{\tau>0}{\mbox{max}} \frac{\mathcal{E}[\sum_{t=0}^{\tau}\gamma^tr^i(X_t^i)|X_0^i = x_i]}{\mathcal{E}[\sum_{t=0}^{\tau}\gamma^t|X_0^i = x_i]}
 \end{align}

 The indices $v^i(x^i)$, computed in Equation \ref{eq:git_indices},can then be used to form a policy, where at each timestep the agent selects the option with the highest $v^i(x^i)$. Generally the computation of the Gittins indices is too expensive, however in the Beta-Bernoulli case it is actually possible \cite{kaufmann2012bayesian}. Traditionally, the indices are computed offline using a variety of methods \cite{weber1992gittins}, we chose to use the restart method proposed by Katehakis et al. \cite{katehakis1987multi} due to its ability to be implemented in a dynamic programming fashion. 
 
\begin{algorithm}
 \KwResult{Current Best Arm, $\Gamma^*$ }
 For Beta(1,1) prior, Table of Indices $v$, Discount Factor $\gamma$: \\
\For{ t=1,2,...}{ 
 Pull arm $k = \underset{x_k \in X}{\mbox{argmax}} v(x_k)$\\
 Observe reward $R_{I_t,t} \in \lbrace 0,1 \rbrace$\\
 Update posterior:\\
 Set $S_{I_t,t+1} = S_{I_t,t} + R_{I_t,t}$ \\
 Set $F_{I_t,t+1} = F_{I_t,t} + 1 - R_{I_t,t}$\\
 Set $x_k = \lbrace 1 + S{I_t,t+1}, 1+F_{I_t,t+1} \rbrace$\\	
}
 \caption{The Gittins Index Method for Beta-Bernoulli Process}
\end{algorithm}

\subsection{Thompson Sampling}
Computation of the Gittins indices can increase exponentially in as the discount factor approaches $1$. Thus, it is not ideal in most cases to use. 
An alternative known as Thompson Sampling is a Bayesian method for the multi-armed bandit problem. We will describe it now in detail for the Beta-Bernoulli process. All arms are initialized with a prior Beta distributions, which is normally Beta($\alpha=1$,$\beta =1$) to reflect a uniform prior on the $\theta$ of the Bernoulli distribution. Then for each arm draw $\theta_{j,t} \sim \mbox{Beta}(\alpha,\beta)$ and pull the arm with the highest $\theta_{j,t}$ drawn. The reward, $X_{i,t}$ is observed from that arm, $j$, and the corresponding Beta distribution is updated. This is repeated until a stopping time is reached. The full algorithm is shown in Algorithm 1.  

The stochastic nature of Thompson sampling makes it less prone to local solutions because of its stochastic nature. Thus, for cases where exploration and exploitation are decoupled Thompson sampling can find a better arm faster. Thompson sampling has recently been shown to approach the Lai and Robbins bound \cite{agrawal2011analysis} and has  empirically been shown to outperform frequentist methods like UCB in certain settings \cite{chapelle2011empirical}. Variants of it are even used commercially in products like Microsoft's adPredictor, which is used by Bing, the search engine, \cite{graepel2010web}. 
\begin{algorithm}
 \KwResult{Current Best Arm, $\Gamma^*$ }
 For Beta(1,1) prior: \\
\For{ t=1,2,...}{ 
 Draw $\theta_{j,t} \sim$ Beta($S_{j,t}+1$,$F_{j,t}+1$) for $j = 1,...,k$\\
 Play $I_t=j$ for $j$ with maximum $p_{j,t}$\\
 Observe reward $X_{I_t,t} \in \lbrace 0,1 \rbrace$\\
 Update posterior:\\
 Set $S_{I_t,t+1} = S_{I_t,t} + X_{I_t,t}$ \\
 Set $F_{I_t,t+1} = F_{I_t,t} + 1 - X_{I_t,t}$\\
	
 }
 \caption{Thompson Sampling for Beta-Bernoulli Process}
\end{algorithm}





 .
\section{Experiments}
For the experiments we used the Brown Vision Lab 2D dataset \cite{brown}, the same used in \cite{christopoulos2007handling}. We downsampled the image by a factor of 2 to create a 40 x 40 occupancy map, which holds 1 if the point cloud was observed and 0 if it was not observed, and a measurement noise map, which holds the variance 0-mean noise added to the SDF values. The parameters of the GPIS were selected using maximum likelihood on a held-out set of validation shapes. The noise of the motion, position and friction coefficient was set to the following variances $\sigma_{mu} = 0.4$, $\sigma_{rot} = 0.3$ rads,$\sigma_{trans} = 3$. Our visualization technique follows the approach of \cite{mahler2015gp} and consisted of drawing many shape samples from the distribution and blurring accordingly to a histogram equalization scheme. 

We did experiments for the case of two hard contacts in 2-D. We drew random lines of actions $\gamma_1(t)$ and $\gamma_2(t)$ by sampling around a circle with radius $\sqrt{2}n$ and sampling the circles origin, then projecting onto the largest inscribing circle in the workspace. 

\subsection{Multi-Armed Bandit Experiments}
We consider the problem of selecting the best grasp plan, $\Gamma^*$ out of a set $G$. For our experiments we look at selecting the best grasp out of a size of $|G| = 1000$. We initialize all algorithms by sampling each grasp 1 time. We draw samples from our graphical model using the technique described in Sec.  \ref{sec:grasp_sample}. In Fig. \ref{fig:grasp_quality}, we plotted the probability of force,$P_F$ closure of the grasp chose vs. stopping time $T_s$ averaged over 100 randomly selected shapes in the Brown Vision Lab 2D dataset and compare the different methods (Thompson, Gittins, Kehoe et al. \cite{kehoe2012toward} and Monte-Carlo Integration).   We then show the grasps selected for five shapes at a stopping time of $T = 9000$ for all the methods listed in Fig. \ref{fig:shape_samples}.

  Interestingly in Fig \ref{fig:grasp_quality}, Gittins and Thompson suggest on average higher quality grasps with  than Monte-Carlo integration and the method listed in Kehoe et al \cite{kehoe2012toward} with the same number of samples drawn . In Fig. \ref{fig:pulls_per_grasp} we plot samples per grasp quality, Gittins and Thompson appear to allocate significantly more grasp samples to grasps of high quality, thus they are quickly able to ignore the low quality grasps. Kehoe et al. and Monte-Carlo integration take a more evenly distributed approach to sample allocation, which could explain the performance difference in Fig. \ref{fig:simple_regret} and Fig. \ref{fig:grasp_quality}.


\begin{figure}[ht!]
\centering
\includegraphics[width = 8cm, height = 9cm]{matlab_figures/pfc.eps}
\caption{ \footnotesize Comparison of the current average probability of force closure vs. the number of samples pulled.Graph is averaged over 100 shapes randomly drawn from the Brown Vision 2D Lab Dataset \cite{brown} with a set $|G|=1000$ for each shape.  We demonstrate this for Thompson, Gittins, Monte-Carlo and the approach taking in Kehoe et al \cite{kehoe2012toward}. We also demonstrate what the average probability of force closure for the approximate optimal policy. Empirically, it appears that Thompson and Gittins converge at a faster rate to the optimal solution, which is desired for an anytime algorithm  }
\vspace*{-10pt}
\label{fig:grasp_quality}
\end{figure}





\begin{figure}[ht!]
\centering
\includegraphics[width = 8cm, height = 9cm]{matlab_figures/pulls_per_grasp.eps}
\caption{ \footnotesize Comparison of sample per grasp for the four sequential decision methods (Monte-Carlo, Thompson, Gittins). Graph is averaged over 100 shapes from the Brown Silhouette Dataset \cite{brown} with a set $|G|=1000$ for each shape. The best grasps are ranked 1 and worst are 1000. As illustrated the MAB algorithms intelligently allocate samples towards high quality grasps based on past observations, where Monte-Carlo Integration takes a uniform approach to allocation. }

\vspace*{-10pt}
\label{fig:pulls_per_grasp}
\end{figure}

\begin{figure*}%
    \centering
    \subfloat{{\includegraphics[width=16.5cm]{matlab_figures/shape_1.eps} }}%
    \qquad
    \subfloat]{{\includegraphics[width=16.5cm]{matlab_figures/shapes_2.eps} }}%
       \subfloat]{{\includegraphics[width=16.5cm]{matlab_figures/shapes_3.eps} }}%
          \subfloat]{{\includegraphics[width=16.5cm]{matlab_figures/shapes_4.eps} }}%
             \subfloat]{{\includegraphics[width=16.5cm]{matlab_figures/shapes_5.eps} }}%
    
    \caption{Five shapes shown from the Brown Visual Lab Dataset with induced shape uncertainity and visualized according to the method described in \cite{mahler2015gp}. The four methods (Monte-Carlo, Kehoe's, Thompson and Gittins) were all run until a stopping time of 9000 evaluations with a uniformly initialized grasp set of $|G|=1000$. We also showed the estimated best grasp in the set.  The grasps and the quality each one found is shown above.  In the four out of five cases, Thompson sampling is able to find the best grasp in the set at the stopping interval of $9000$, however at the last shape there is a difference of $2\%$ grasp quality.   }%
    \label{fig:shape_samples}%
\end{figure*}

\todo{Michael: Need to discuss how to implement worst case scenario, adversial applies changing distributions online (which would not model the problem).}


\subsection{Sensitivity Analysis }
We now will show how well the top two algorithms Thompson Sampling and the Gittens Index Method perform under a variation in noise from friction coefficient uncertainty, shape uncertainty, rotational pose and translation pose. The experiments are performed with the same setup as before but now we increase the variance parameters across a set range for each parameter to simulate low, medium and high levels of noise. All experiments were averaged across 10 shapes randomly selected with from the Brown dataset with a set size $|G| = 1000$. 

For friction coefficient we varied the variance across the following values $\sigma_{\mu} = \lbrace 0.05, 0.2, 0.4 \rbrace$. As illustrated in Fig. \ref{fig:fric_sens}, the performance of the bandit algorithm remains largely unchanged, with typical convergence to zero in simple regret less than 2000 evaluations.

For rotational uncertainty in pose, we varied $\sigma_{rot}$ over the set of $\lbrace 0.03, 0.12,0.24\rbrace$ radians. As illustrated in Fig. \ref{fig:rot_sens}, the performance of the bandit algorithms is effected by the change in rotation, increase in variance to $0.24$ radians or $13^{\deg}$  causes the convergence in simple regret to not be reached until 5500 samples or an average of 5.5 samples per grasp. This can be explained because such a large variance causes a a drop in quality across all grasps and makes it harder to separate the outliers \cite{gabillon2012bes}. The quality of the best grasp along with the grasp for each round is shown in \ref{fig:rot_shapes}. 


For translational uncertainty in pose, we varied $\sigma_{trans}$ in the range of $\lbrace 3,12, 24 \rbrace$ units (on a 40 x 40 unit workspace). As you can see in Fig. \ref{fig:rot_sens}, the performance of the bandit algorithms is effected by the change in rotation, increase noise of $\sigma_{trans} = 24$ causes the convergence to not be reached until around 5000 samples for the Gittens Method and  8200 evaluations for Thompson Sampling.



\subsection{Worst Case Scenario}
The MAB algorithms use the observations of samples drawn to decide which grasp to sample next from. To show worst case performance under such a model, we sorted the quality of all 1000 grasps offline and arranged the order of samples, so that the top 500 grasps have samples drawn in the order of worst to best and the bottom 500 grasps have samples drawn in order of best to worst. The intent here is to provide misleading observations to the bandit algorithms. We demonstrate in Fig. \ref{fig:worst_case} a case where the observations are misleading. 

As illustrated in Fig. \ref{fig:worst_case}, all the methods are effected by this worst case performance. It would appear that when the observations are misleading the best thing to do is simply uniform allocation of grasp samples. It should also be noted though that of the three algorithms measured against Monte-Carlo integration, Thompson sampling is able to  eventually recover from this scenario.  

\todo{running experiments today on this}

\begin{figure}[ht!]
\centering
\includegraphics[width = 8cm, height = 9cm]{matlab_figures/worst_case.eps}
\caption{ \footnotesize Comparison of Simple Regret convergence for the four sequential decision methods (Monte-Carlo, Bayes -UCB, Thompson and Gittins). Graph is averaged over 100 shapes from the Brown Sillohoute Dataset \cite{brown} with a set $|G|=1000$ for each shape. As you can see the BMAB methods converge almost a magnitude faster than random allocation. It is worth noting that Gittins outperform the other two algorithms, which is useful when choosing which one to implement }
\vspace*{-10pt}
\label{fig:worst_case}
\end{figure}


\begin{table*}[t]
\centering
\begin{tabular}{ |p{4cm}||p{2cm}|p{2cm}|p{2cm}|  }
 \hline
 \multicolumn{4}{|c|}{Sensitivity Analysis for Thompson Sampling} \\
 \hline
Uncertainty Type & Low Uncertainty & Medium Uncertainty & High Uncertainty\\
 \hline
Translation Variance in Pose & 1210    & 2207 &  8763\\
Friction Coefficient Variance &  1985  & 1456   & 1876\\
Rotational Variance in Pose& 4230 & 4431 &  4432\\
 \hline
\end{tabular}
   \caption { \footnotesize  Sensitivity Analysis for Thompson Sampling and the Gittens Index Method under rotational variance $\sigma_{rot} = \lbrace 0.03,0.12, 0.24 \rbrace$ radians,  translation uncertainty $\sigma_{trans} = \lbrace 3, 12, 24 \rbrace$ units  friction coefficient uncertainty $\sigma_{fric} = \lbrace 0.05,0.2, 0.4 \rbrace$  from left to right on a 40 x 40 unit workspace averaged over 100 shapes from the Brown Vision Lab Data set. The sensitivity analysis shows that large variance in translational uncertainty in pose can increase the amount of iterations needed for the bandit algorithm to converge to the highest quality grasp in the set. 
   }
		\tablabel{opt-p-comparison}
\vspace*{-20pt}
\end{table*}

\section{Limitations} 

Our budgeted multi-armed bandit approach appears promising, but we still do not know how well it will perform on 3D shapes and large scale grids. Future work will be building an efficient construction of GPIS to scale to 3D and test the bandit method there. 

Of the BMAB algorithms we showed, Thompson Sampling is guaranteed to find the best grasp as the stopping time approaches infinity \cite{agrawal2011analysis} but when do you terminate the algorithm is still an open question. Fixed confidence methods do exist that terminate when a certain confidence interval is reached \cite{maron1993hoeffding} \cite{mnih2008empirical}. However, a known problem is that if two grasps have very similar quality it could greatly increase the time for needed to reach the statistical confidence interval \cite{audibert2010best}. We proposed treating the BMAB as anytime algorithm and initial results in Fig. \ref{fig:grasp_quality} suggest that on average grasps at a given stopping time are better than prior methods of Monte-Carlo sampling or the approach of Kehoe et al. However, as shown in Fig. \ref{fig:worst_case} there can exists pathological cases that can mislead bandit algorithms to focus samples on the wrong grasps. Fortunately, though these cases occur with a small probability, however it is important for a practitioner to be aware of them. 

Another problem that was revealed in our analysis was that our current grasp metric, probability of force closure, is not dependent on the center of mass \cite{ferrari1992}. It only measure the probability that a grasp controller can resist any force provided it can exert an infinite force.  One can assume that the grasp controller on a robot hand is powerful enough to apply the proper resistance, but that assumption might be invalid in some applications. A similar metric that is still from Beta-Bernoulli and takes center of mass into account, would be ideal for both accurate grasp quality prediction under uncertainty and the utilization of MAB algorithms.  Recent work by Kim et al. developed a physics based simulator that could potentially achieve this goal \cite{kim2012physically}. 

\section{Conclusion}
Assessing grasp quality under  uncertainty is computationally expensive as it often requires repeated evaluations of the grasp metric over many random samples.
In this work, we proposed a multi-armed bandit approach to efficiently identify high-quality grasps under uncertainty in shape, pose, friction coeffiecient and motion. 
A key insight from our work is that uniformly allocating samples to grasps is inefficient, and
 we found that a MAB approach prioritizes evaluation of high-quality grasps while quickly pruning-out obviously poor grasps.
A pre-requisite for applying a bandit approach is to formulate a representation  of how uncertainty affects grasp parameters and thus grasp quality.
We purpose treating this as a graphical model and use model the parameters as stochastic noise. Our choice of distributions though is not the focus of the paper. The MAB algorithm is applicable in any context of bounded reward distributions and all the theoretical results we mentioned will transfer to the Beta-Bernoulli case, or the estimation of probability of force closure. 

One of the BMAB algorithms that works well in practice, Thompson Sampling, is guaranteed to find the best grasp in a given proposal set in the limit of an infinite time \cite{agrawal2011analysis} and initial results have shown it to outperform the methods of prior work Monte-Carlo and the method purposed by Kehoe et al. \cite{kehoe2012estimating}. 



\section{Future Work}

As we scale to larger 3D objects the possible number of grasp candidates will be substantially larger, the more options a MAB algorithm has leads to generally a harder problem \cite{bubeck2009pure}. The MAB algorithms presented above though assumed that each option is independent. In the grasping context though spatial information about grasps could provide information about the quality of similar grasps. For example, if grasp $A$ is very similar with respect to some metric to grasp $B$ and grasp $B$ appears promising based on samples observed, we might be able use this information and update the prior Beta distribution of grasp $A$.

MAB methods with correlated options do exist and have even been shown to achieve sub-logarithmic regret in some cases \cite{reverdy2014modeling}. However, there is an assumption that the correlation between the different options is known or estimated  a priori to running the algorithm. In the grasping context, one way to achieve this would be to learn correlations based on an offline training method \cite{andrieu2003introduction}, this might require a feature based representation though of both the proposed grasps and the object itself which could lead to many interesting research questions.

Future work will also consider applying BMAB approach to grasp planners like GraspIt! \cite{miller2004graspit} to see if our method can handle uncertainty while working under the time constraints needed for most real time applications. While our results are promising, it remains to be seen how well it deals with the increased complexity of 3D models over 2D models and larger scale experiments. However, the BMAB model has a large amount of literature to draw from as we encounter new and more challenging problems \cite{bergemann2006bandit}.


\bibliographystyle{IEEEtranS}
\bibliography{references}



\end{document}
